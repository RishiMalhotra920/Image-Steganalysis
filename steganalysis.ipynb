{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nfrom sklearn.model_selection import GroupKFold\nimport cv2\nimport os\nimport time\nimport random\nimport pandas as pd\nimport numpy as np\n\n\n# from mlxtend.plotting import plot_learning_curves\n# plot_learning_curves\n\n!pip install efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import datasets, models, transforms\nimport torchvision.transforms.functional as TF\nimport matplotlib.pyplot as plt\n# from PIL import Image\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom sklearn.model_selection import learning_curve\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nBASE_PATH = \"/kaggle/input/alaska2-image-steganalysis\"\nDATA_ROOT_PATH = '../input/alaska2-image-steganalysis'\nRESNET_MODEL_PATH = '../input/newresnetmodel/resnet18modelv1.pth'","execution_count":2,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: efficientnet_pytorch in /opt/conda/lib/python3.7/site-packages (0.6.3)\r\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\r\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\r\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.1)\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Notes - to load resnet18\n#resnet = load_model('resnet18')\n# resnet = load_checkpoint(resnet, RESNET_MODEL_PATH).to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(name):\n    \"\"\"\n    Load basic resnet34/ resnet18 from the internet\n    \"\"\"\n    #loading resnet34\n    if name == 'resnet34':\n        model = models.resnet34(pretrained=True)\n    elif name == 'resnet18':\n        model = models.resnet18(pretrained=True)\n    elif name == 'effnet':\n        model = EfficientNet.from_pretrained('efficientnet-b0')\n        \n    #to only finteune the top layer of the model\n    for param in model.parameters():\n        param.requires_grad = False\n\n\n    # Replace the top layer for finetuning.\n    model.fc = nn.Linear(model.fc.in_features, 4)  # 100 is an example.\n    model = model.to(device)\n    return model","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"effnet = load_model('effnet')","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/checkpoints/efficientnet-b0-355c32eb.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=21388428.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f97f42efdd741469770fd5fb5829090"}},"metadata":{}},{"output_type":"stream","text":"\nLoaded pretrained weights for efficientnet-b0\n","name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"'EfficientNet' object has no attribute 'fc'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-638bc611ad39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meffnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'effnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-a56bba9dc3d6>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Replace the top layer for finetuning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 100 is an example.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'EfficientNet' object has no attribute 'fc'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_checkpoint(model, filepath):\n    \"\"\"\n    Loads the weights into the model\n    \"\"\"\n    states_weights = torch.load(filepath, map_location={'cuda:0': 'cpu'})\n    model.load_state_dict(states_weights)\n    #model = checkpoint['model']\n#     model.load_state_dict(checkpoint['state_dict'])\n#     for parameter in model.parameters():\n#         parameter.requires_grad = False\n    \n#     model.eval()\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n    \n    model.eval()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image(idx):\n    image, target = train_dataset[idx]\n    numpy_image = image.permute(1,2,0).cpu().numpy()\n\n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n    ax.set_axis_off()\n    ax.imshow(numpy_image)\n\n#show_image(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = []\n\nfor label, kind in enumerate(['Cover', 'JMiPOD', 'JUNIWARD', 'UERD']):\n    for path in glob('../input/alaska2-image-steganalysis/Cover/*.jpg'):\n        dataset.append({\n            'kind': kind,\n            'image_name': path.split('/')[-1],\n            'label': label\n        })\n\nrandom.shuffle(dataset)\ndataset = pd.DataFrame(dataset)\ngkf = GroupKFold(n_splits=5)\ndataset.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(gkf.split(X=dataset.index, y=dataset['label'], groups=dataset['image_name'])):\n    dataset.loc[dataset.iloc[val_index].index, 'fold'] = fold_number\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, kinds, image_names, labels, transforms=None):\n        super().__init__()\n        self.kinds = kinds\n        self.image_names = image_names\n        self.labels = labels\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        kind, image_name, label = self.kinds[index], self.image_names[index], self.labels[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{kind}/{image_name}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n        target = label\n        return image, target\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]\n\n    def get_labels(self):\n        return list(self.labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_number = 0\ntrain_dataset = DatasetRetriever(\n    kinds=dataset[dataset['fold'] != fold_number].kind.values,\n    image_names=dataset[dataset['fold'] != fold_number].image_name.values,\n    labels=dataset[dataset['fold'] != fold_number].label.values,\n    transforms=get_train_transforms(),\n)\n\nvalidation_dataset = DatasetRetriever(\n    kinds=dataset[dataset['fold'] == fold_number].kind.values,\n    image_names=dataset[dataset['fold'] == fold_number].image_name.values,\n    labels=dataset[dataset['fold'] == fold_number].label.values,\n    transforms=get_valid_transforms(),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 5\nbatch_size = 16\nlearning_rate = 0.01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\nfrom collections import namedtuple\nfrom itertools import product\n\nclass RunBuilder():\n    @staticmethod\n    def get_runs(params):\n        \n        Run = namedtuple('Run', params.keys())\n\n        runs = []\n        for v in product(*params.values()):\n            runs.append(Run(*v))\n        \n        return runs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Epoch():\n    def __init__(self):\n        self.count = 0\n        self.loss = 0\n        self.start_time = None\n    \nclass Run():\n    def __init__(self):\n        self.params = None\n        self.count = 0\n        self.data = []\n        self.start_time = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelsAndPreds():\n    @staticmethod\n    def transform_labels_for_metric(labels):\n        \n        return torch.clamp(labels, min=0, max=1).detach().numpy()\n        \n        \n    @staticmethod\n    def transform_preds_for_metric(preds):\n        \n        preds = nn.Softmax()(preds)\n        mx, indices = torch.max(preds, 1)\n        mask = (indices!=0).to(torch.float) - (indices==0).to(torch.float) \n        preds = mask*mx\n        \n        return preds.detach().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import clear_output, display\n\nclass RunManager():\n    def __init__(self):\n        self.epoch = Epoch()\n        self.run = Run()\n        \n        self.preds = None\n        self.labels = None\n        self.network = None\n        self.loader = None\n        self.runs_losses = []\n    \n    \n    def begin_run(self, run, network, loader):\n        \n        self.run.start_time = time.time()\n        self.run.params = run\n        self.run.count += 1\n        \n        self.network = network\n        self.loader = loader\n        \n        self.preds = torch.empty(0)\n        self.labels = torch.empty(0)        \n        \n        \n    def end_run(self):\n        self.epoch.count = 0\n        \n        \n    def begin_epoch(self):\n        self.epoch.start_time = time.time()\n        self.epoch.count += 1\n        self.epoch.loss = 0\n        \n    \n    def end_epoch(self):\n        epoch_duration = time.time() - self.epoch.start_time\n        run_duration = time.time() - self.run.start_time\n        \n        loss = self.epoch.loss / len(self.loader.dataset)\n        \n        score = self.alaska_auc()\n        results = OrderedDict()\n        results [\"run_count\"] = self.run.count\n        results['epoch_count'] = self.epoch.count\n        results['loss'] = loss\n        results['score'] = score\n        results['epoch_duration'] = epoch_duration\n        results['run_duration'] = run_duration\n        \n        for k,v in self.run.params._asdict().items():\n            results[k] = v #eg: results['lr'] = 0.1\n        \n        self.run.data.append(results)\n        df = pd.DataFrame.from_dict(self.run.data, orient='columns')\n        \n        clear_output(wait=True)\n        display(df)\n    \n    \n    def track_loss(self, loss):\n        self.epoch.loss += loss.item() * self.loader.batch_size\n        \n        \n    def track_metric(self, labels, preds):\n        self.labels = torch.cat((self.labels, labels.cpu().to(torch.float32)))\n        self.preds = torch.cat((self.preds, preds.cpu()))\n        \n        \n    def save_and_return_df(self, fileName): #doesn't work\n        \n        df = pd.DataFrame.from_dict(\n            self.run.data\n            ,orient='columns'\n        )\n        df.to_csv(f'{fileName}.csv')\n#         with open(f'{fileName}.json','w',encoding='utf-8') as f:\n#             json.dump(self.run.data, f, ensure_ascii=False, indent=4)\n        \n        return df    \n        \n    def alaska_auc(self):\n        \"\"\"\"\n        return the alaska_metric error\n        \"\"\"\n        if len(self.labels) == 0 or len(self.preds) == 0:\n            return -1\n        labels = LabelsAndPreds.transform_labels_for_metric(self.labels)\n        preds = LabelsAndPreds.transform_preds_for_metric(self.preds)\n        \n        tpr_thresholds = [0.0, 0.4, 1.0]\n        weights = [2, 1]\n        fpr,tpr,thresholds= metrics.roc_curve(labels,preds)\n\n        areas=np.subtract(tpr_thresholds[1:],tpr_thresholds[:2])\n        normalization=np.dot(areas,weights)\n        competition_metric = 0\n        for idx, weight in enumerate(weights):\n            y_min = tpr_thresholds[idx]\n            y_max = tpr_thresholds[idx + 1]\n            mask = (y_min < tpr) & (tpr < y_max)\n\n            if(mask.sum()==0):\n                continue\n            x_padding = np.linspace(fpr[mask][-1], 1, 100)\n            x = np.concatenate([fpr[mask], x_padding])\n            y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n            y = y - y_min # normalize such that curve starts at y=0\n            score = metrics.auc(x, y)\n            submetric = score * weight\n            best_subscore = (y_max - y_min) * weight\n            competition_metric += submetric\n        return competition_metric / normalization\n    \n    def plot_confusion_matrix(self):\n        \"\"\"\n        Plots the confusion matrix between labels and predictions.\n        Labels are multiclass. Eg: [0,1,2,2,3,1,2,1,0]\n        Predictions are multiclass. Eg: [0,1,2,2,3,1,2,1,0]\n        len(labels) == len(predictions)\n\n        @param labels - the truths. Numpy array\n        @param predictions - the predictions by your model. Numpy array\n        \"\"\"\n        assert len(self.labels) == len(self.preds)\n        names = ('Cover', 'JMiPOD', 'JUNIWARD', 'UERD')\n        mutliclass_preds = torch.argmax(self.preds,dim = 1)\n        cm = confusion_matrix(self.labels.detach().numpy(), mutliclass_preds.detach().numpy())\n        df_cm = pd.DataFrame(cm, index = [i for i in names],\n                          columns = [i for i in names])\n        plt.figure(figsize = (10,7))\n        drawing = sn.heatmap(df_cm, annot=True)\n        drawing.set(xlabel='Predictions', ylabel='True')\n    \n    def get_loss(self):\n        return self.epoch.loss / len(self.loader.dataset) #the loss for the last epoch is the loss for the run","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(manager, params, num_epochs):\n    \n    for run in RunBuilder.get_runs(params):\n        #Loss and optimizer\n        criterion = nn.CrossEntropyLoss().to(device)\n        optimizer = torch.optim.Adam(run.network.parameters(), lr=run.lr)\n        \n        altered_train_dataset = torch.utils.data.Subset(train_dataset, list(range(run.m)))\n        train_loader = torch.utils.data.DataLoader(dataset=altered_train_dataset\n                                                   ,batch_size=run.batch_size \n                                                   ,shuffle=True\n                                                   ,num_workers = 2)\n        \n        manager.begin_run(run, run.network, train_loader)\n        for epoch in range(num_epochs):\n            manager.begin_epoch()\n            for i, batch in enumerate(train_loader):\n                images = batch[0].to(device)\n                labels = batch[1].to(device)\n                preds = run.network(images)\n                loss = criterion(preds, labels)\n                optimizer.zero_grad()\n                loss.backward()            \n                optimizer.step()\n\n                manager.track_loss(loss)\n#                 manager.track_metric(labels, preds)\n            \n            manager.end_epoch()\n            \n        manager.end_run()\n    \n    print('Finished Training')\n    df = manager.save_and_return_df('train_results')\n    run_loss = manager.get_loss()\n    return df, run_loss\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cross_validate(manager, params):\n    \"\"\"\n    \"\"\" \n    with torch.no_grad():\n        for run in RunBuilder.get_runs(params):\n            \n            criterion = nn.CrossEntropyLoss().to(device)\n            \n            altered_validation_dataset = torch.utils.data.Subset(validation_dataset, list(range(run.m)))\n\n            validation_loader = torch.utils.data.DataLoader(dataset=altered_validation_dataset,\n                                           batch_size=run.batch_size, \n                                           shuffle=True,\n                                           num_workers = 2)\n            \n            manager.begin_run(run, run.network, validation_loader)\n            manager.begin_epoch() #only one epoch needed in cross validation set\n            for i, batch in enumerate(validation_loader):\n                images = batch[0].to(device)\n                labels = batch[1].to(device)\n                preds = run.network(images)\n                loss = criterion(preds, labels)\n\n                manager.track_loss(loss)\n#                 manager.track_metric(labels, preds)\n\n            manager.end_epoch()\n            manager.end_run()\n\n    print('Finished Validating')\n    df = manager.save_and_return_df('train_results')\n    run_loss = manager.get_loss()\n\n    return df, run_loss\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet = load_model('effnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_params = OrderedDict(\n        network = [resnet]\n        ,m = [len(train_dataset)] # len(train_dataset) for full training\n        ,lr = [.001]\n        ,batch_size = [8]\n)\ntrain_manager = RunManager()\ntrain_df, train_loss = train(train_manager, train_params, num_epochs=7)\ntrain_df.sort_values(by='score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_params = OrderedDict(\n        network = [resnet]\n        ,m = [len(validation_dataset)] #len(validation_dataset) for full validation\n        ,batch_size = [8]\n)\ncv_manager = RunManager()\ncv_df, _ = cross_validate(cv_manager, cv_params)\ncv_df.sort_values(by='score', ascending=False)\ncv_manager.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Diagnosing model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def diagnose(set_sizes):\n    \n    train_params = OrderedDict(\n        network = None\n        ,m = None #the first m examples of dataset to train on.\n        ,lr = [.001]\n        ,batch_size = [16]\n        )\n    cv_params = OrderedDict(\n        network = None\n        ,m = None #the first m examples of dataset to train on\n        ,batch_size = [32]\n    )\n    train_losses = []\n    cv_losses = []\n    models = []\n    for m in set_sizes:\n        resnet = load_model('resnet34')\n        \n        train_params['network'] = [resnet]\n        train_params['m'] = [m]\n        cv_params['network'] = [resnet]\n        cv_params['m'] = [m]\n        \n        train_manager = RunManager()\n        cv_manager = RunManager()\n        \n        _, train_loss = train(train_manager, train_params, num_epochs=7)\n        _, cv_loss = cross_validate(cv_manager, cv_params)\n        train_losses.append(train_loss)\n        cv_losses.append(cv_loss)\n        models.append(resnet)\n    return models, train_losses, cv_losses\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_learning_curves(set_sizes, train_losses, cv_losses):\n    \"\"\"\n    @param set_sizes: list containing the different set sizes used\n    @param train_losses: the train loss corresponding to the set sizes\n    @param cv_losses: the cv loss corresponding to the set sizes\n    \n    When training and validating on train and validation sets with size set_sizes[i],\n    the train_loss is  train_losses[i] and cv loss is cv_loss[i]\n    \"\"\"\n    # plt.plot(train_set_sizes, train_runs_losses)\n    plt.plot(set_sizes, train_losses, label='Train Loss')\n    plt.plot(set_sizes, cv_losses, label='CV Loss')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set_sizes = [i for i in range(0, len(validation_dataset)+1, 10000)]\n# set_sizes[0] = 1\n# models, train_losses, cv_losses  = diagnose(set_sizes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(train_losses)\n# print(cv_losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set_sizes = [10000, 20000, 30000, 40000, 50000, 60000] \n# train_losses = [1.3995465944290162, 1.4217510432243348, 1.4290748152414958, 1.4270348804950714, 1.428084383506775, 1.4317004181861877] \n# cv_losses = [1.4482383392333984, 1.4100874675750732, 1.4082810043334961, 1.4243976655960082, 1.4023886753082275, 1.420537694867452]\n# draw_learning_curves(set_sizes, train_losses, cv_losses)\n\n# print(len(models)) [ model1, model2,...]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# draw_learning_curves(set_sizes, train_losses, cv_losses)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetSubmissionRetriever(Dataset):\n\n    def __init__(self, image_names, transforms=None):\n        super().__init__()\n        self.image_names = image_names\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_name = self.image_names[index]\n        image = cv2.imread(f'{BASE_PATH}/Test/{image_name}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        return image_name, image\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = DatasetSubmissionRetriever(\n    image_names=np.array([path.split('/')[-1] for path in glob('../input/alaska2-image-steganalysis/Test/*.jpg')]),\n    transforms=get_valid_transforms(),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(network):\n    \"\"\"\n    Return array containing the predictions\n    \"\"\"\n    test_data_loader = DataLoader(\n        test_dataset,\n        batch_size=8,\n        shuffle=False,\n        num_workers=2,\n        drop_last=False,\n    )\n    total_step = len(test_data_loader)\n    result = {'Id': [], 'Label': []}\n    with torch.no_grad():\n        for i, (image_names, images) in enumerate(test_data_loader):\n            print(f'Progress: {round(100*i/(total_step-1),1)}%', end='\\r')\n    \n            preds = network(images.to(device))\n            preds = preds.cpu()\n            preds = LabelsAndPreds.transform_preds_for_metric(preds)\n            \n            result['Id'].extend(image_names)\n            result['Label'].extend(preds)\n\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = test(resnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(result)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}